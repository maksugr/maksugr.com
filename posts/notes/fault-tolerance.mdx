---
title: 'Fault tolerance'
summary: 'Fault tolerance summary'
topics: ['fault tolerance']
publishedAt: '2022-04-25'
---

## Definitions

The terms *failure* and *fault* are key to any understanding of system reliability. Yet they are often misused.

Over time, failure has come to be defined in terms of specified service delivered by a system. This avoids circular definitions involving essentially synonymous terms such as *defect*. A system to have a **failure** if the service it delivers to the user deviates from compliance with the system specification for a specified period of time. While it may be difficult to arrive at an unambiguous specification of the service to be delivered by any system, the concept of an agreed-to specification is the most reasonable of the options for defining satisfactory service and the absence of satisfactory service, failure.

It is important to have some reference for the definition of failure, and the specification is a logical choice. The specification can be considered as a boundary to the system's [region of concern](#region-of-concern). It is important to recognize that every system has an *explicit specification*, which is written, and an *implicit specification* that the system should at least behave as well as a reasonable person could expect based on experience with similar systems and with the world in general. Clearly, it is important to make as much of the specification as explicit as possible.

It has become the practice to define faults in terms of failures. The concept closest to the common understanding of the word fault is one that defines a **fault** as the adjudged cause of a failure. This fits with a common application of the verb form of the word fault, which involves determining cause or affixing blame. However, this requires an understanding of how failures are caused.

An alternate view of faults is to consider them failures in other systems that interact with the system under consideration:

* a subsystem internal to the system under consideration
* a component of the system under consideration
* an external system that interacts with the system under consideration
* the environment

In the first instance, the link between faults and failures is cause; in the second case it is level of abstraction or location.

The advantages of defining faults as failures of component/interacting systems are:

* one can consider faults without the need to establish a direct connection with a failure, so we can
discuss faults that do not cause failures, i.e., the system is naturally fault tolerant
* the definition of a fault is the same as the definition of a failure with only the boundary of the relevant
system or subsystem being different

This means that we can consider an obvious internal defect to be a fault without having to establish a causal relationship between the defect and a failure at the system boundary.

A fault can lead to:

* other faults
* failure
* nothing

A system with faults may continue to provide its service, that is, not fail. Such a system is said to be **fault tolerant**. Thus, an important motivation for differentiating between faults and failures is the need to describe the fault tolerance of a system. An observer inspecting the internals of the system would say that the faulty component had failed, because the observer's viewpoint is now at a lower level of detail.

The observable effect of a fault at the system boundary is called a **symptom**. The most extreme symptom of a fault is a failure.

The term **error** often is used in addition to the terms fault and failure. Often, errors are defined to be the result of faults, leading to failures. Informally, errors seem to be a passive concept associated with incorrect values in the system state. However, it is extremely difficult to develop unambiguous criteria for differentiating between faults and errors. Many researchers refer to value faults, which are also clearly erroneous values. The connection between error and failure is even more difficult to describe.

As we have seen, differentiation between failures and faults is essential for fault tolerant systems. A third term, error, adds little to this distinction and can be a source of confusion.

## Requirements

To be fault tolerant, [a system](/notes/system) must be able to:

* detect
* diagnose
* confine
* mask
* compensate
* recover

## Degree

The degree of fault tolerance a system requires can be specified [quantitatively](#quantitative-goals) or [qualitatively](#qualitative-goals).

### Quantitative Goals

A quantitative reliability goal is usually expressed as the maximum allowed failure-rate. For example, the reliability figure usually stated as a goal for computer systems in commercial aircraft is less than 10<sup>-9</sup> failures per hour. The problem with stating reliability requirements in this manner is that it is difficult to know when it has been achieved. Standard statistical methods cannot be used to show such reliability with either standard or fault tolerant software. It is also clear that there is no way to achieve confidence that a system meets such a reliability goal through random testing. Nevertheless, reliability goals are often expressed in this manner.

### Qualitative Goals

An alternative method of specifying a system's reliability characteristics is to specify them qualitatively. Typical specifications would include next goals.

#### Fail-safe

Design the system so that, when it sustains a specified number of faults, it fails in a safe mode. For instance, railway signalling systems are designed to fail so that all trains stop.

#### Fail-op

Design the system so that, when it sustains a specified number of faults, it still provides a subset of its specified behavior.

#### No single point of failure

Design the system so that the failure of any single component will not cause the system to fail. Such systems are often designed so that the failed component can be replaced or repaired before another failure occurs.

#### Consistency

Design the system so that all information delivered by the system is equivalent to the information that would be delivered by an instance of a non-faulty system.

## Levels

There are three levels at which fault tolerance can be applied:

- [Hardware](#hardware-fault-tolerance)
- [Software](#software-fault-tolerance)
- [System](#system-fault-tolerance)

### Hardware fault tolerance

Traditionally, fault tolerance has been used to compensate for faults in computing resources. By managing extra hardware resources, the computer subsystem increases its ability to continue operation. Hardware fault tolerance measures include:

* redundant communications
* replicated processors
* additional memory
* redundant power/energy supplies.

Hardware fault tolerance was particularly important in the early days of computing when the time between machine failures was measured in minutes.

### Software fault tolerance

The second level of fault tolerance recognizes that a fault-tolerant hardware platform does not, in itself, guarantee high availability to the system user. It is still important to structure the computer software to compensate for faults such as changes in programs or data structures due to transients or design errors. This is software fault tolerance. Mechanisms such as:

* [checkpoint](#checkpoint)
* [restart](#restart)
* [recovery blocks](#recovery-blocks)
* [multiple-version programs](#multiple-version-programs)

are often used at this level.

#### Checkpoint

#### Restart

#### Recovery blocks

#### Multiple-version programs

### System fault tolerance

At a third level, the computer subsystem may provide functions that compensate for failures in other system facilities that are not computer-based. This is system fault tolerance. For example, software can detect and compensate for failures in sensors. Measures at this level are usually application-specific. It is important that fault tolerance measures at all levels be compatible.

---

#### References

* Walter L. Heimerdinger, Charles B. Weinstock, "A Conceptual Framework for System Fault Tolerance";
